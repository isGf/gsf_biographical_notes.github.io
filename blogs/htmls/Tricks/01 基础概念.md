# 最佳实践指南


## AI基础认知

### 1. 通用大模型和垂类大模型

**通用大模型**
- 通用大模型，即 General AI Model，是指那些经过广泛训练，能够处理多种任务和领域的人工智能模型。这些模型通常基于大规模的数据集，旨在具备一定的普遍性和适应性。
- 优点：能够处理多种任务（如文本生成、翻译、问答等），适合多种应用场景，被广泛应用于自然语言处理、图像识别、语音识别等领域。可以通过微调适应特定需求，支持各种行业的应用。
- 缺点：通用大模型虽然经过大量数据的训练，但这些数据通常无法深入特定领域，并且训练数据来自互联网和其他广泛的文本源，其中可能包含各种偏见、刻板印象和错误信息。这些偏见和错误可能会反映在模型的输出中。

**垂类大模型**
- 垂类大模型是针对特定领域或行业进行优化和训练的人工智能模型。这些模型通常在特定的数据集上进行训练，以便更好地满足行业需求。
- 优点：针对特定数据集进行训练，使其在该领域内表现卓越。由于训练数据的专业性，模型生成的内容通常更少出现错误，能够避免通用模型可能出现的模糊或误导性回答。
- 缺点：由于垂类模型的表现高度依赖于训练数据的质量和数量，若数据不足或存在错误，模型可能无法提供可靠的结果。开发专门的垂类模型需要较高的投入，包括数据收集、标注和持续维护，成本相对较高。

### 2. 大模型的参数及类别

**1. 规模分类**
- 3B和7B分别表示模型的参数量为30亿和70亿。参数数量越多，模型的复杂度和学习能力越强，但也对计算资源有更高要求，且训练时间也更长。

**2. 领域分类**
- 自然语言处理模型：专注于文本相关任务，如 ChatGPT、ChatGLM 等；
- 语音模型：文字相互转换语音任务，如 Chattts 等；
- 多模态模型：可以处理多种非文字数据；如 QwenVL 等；
- 媒体生成模型：文生图、文生视频；如 SD、CogVideo 等；

**3. 开源与闭源**
- 开源模型：允许进行修改和私有化使用，如 Qwen3、Gamma3 等；
- 闭源模型：只能在线使用，但一般拥有超级性能，如 Kimi 1.5、ChatGPT 4等；



## LLM Embedding ReRanker

**1. 大语言模型（LLM）**
- LLM是指通过大规模数据训练的语言模型，能够生成、理解和处理自然语言文本。
- LLM模型用于语义理解和内容生成

**2. 嵌入模型（Embedding）**
- Embedding模型主要用于将词、短语或句子转换为向量形式，以便计算机能够处理和理解。
- Embedding模型提供语义表示

**3. 排序模型（Ranker）**
- Ranker模型用于对候选项进行排序，通常在信息检索或推荐系统中使用。
- Ranker模型确保最相关的内容被优先呈现

---

## Prompt 提示词工程

**1. Prompt对模型的影响**
- Prompt能够引导大模型生成更符合预期的内容，例如身份设定、任务内容等

**2. 不同场景下的Prompt设计**
- 在公司智能助理的场景中，Prompt的设计应注重回答的准确性；在AI答辩场景中，Prompt更应注重用户问答的上下文信息设计。

**3. 如何设计有效的Prompt**
- 设置开场白：让大模型先介绍自己
- 清晰表达：使用“总结以下内容”而不是“说点什么”
- 示范样例：提供示例输入和期望输出，让模型理解格式和风格

**4. 提示词工程学习资源推荐**
- [Prompts(提示词) - 飞书云文档](https://waytoagi.feishu.cn/wiki/Q5mXww4rriujFFkFQOzc8uIsnah?table=tbldSgFt2xNUDNAz&view=vewo2g2ktO)
- [从1000+模板中总结出的10大提示工程方法助你成为提示词大师！ - 知乎](https://zhuanlan.zhihu.com/p/665165976)

---

## RAG 检索增强生成

**1. RAG 技术定义**

RAG（Retrieve-Augment-Generate）技术是一种基于检索、增强和生成的文本生成方法。通过结合检索模型和生成模型，提高文本生成的准确性和连贯性。

- Retrieval 检索：信息检索。主要任务是从外部知识库中检索相关信息。帮助模型找到与用户查询相关的事实或数据，为生成提供背景信息。

- Augmented 增强：将检索的信息和模型能力以及Prompt结合起来，提供额外的上下文，增强生成模型的回答能力，使得生成的内容更加准确和相关。

- Generation 生成：模型利用先前的步骤所获取的知识来生成流畅且符合上下文的回答。

**2. 知识库**
- 知识库（Knowledge）是一些文档的集合。一个知识库可以被整体集成至一个应用中作为检索上下文使用。
- 大模型在语言生成和上下文理解方面，由于过度依赖于固定的预训练数据，它们在回答需要特定领域的问题时，可能会出现“编造”信息的现象，导致生成结果不准确或缺乏事实依据。

**3. 知识图谱**
- 基本概念：知识图谱（Knowledge Graph，KG）是一种揭示实体之间关系的语义网络，可以对现实世界的事物及其相互关系进行形式化地描述。
- 知识图谱是什么：
```markdown
1.知识图谱是一个存储信息的方法
2.描述的是事实
3.核心表达的是实体和关系
4.可以有多种实体和关系
```

- 知识图谱的缺点：
```markdown
1.知识图谱构建工作量大
2.大模型生成知识图谱本身就会有幻觉问题
3.知识更新难度极大
4.知识图谱的查询效率低
```

**4. 知识库和知识图谱结合**
- 知识库的问题：知识库中的数据检索通常依赖于关键词匹配，可能导致检索结果不够精确或不够丰富。
- 知识图谱的问题：知识图谱在某些专业领域的构建可能会受到数据的限制，无法覆盖所有细节。
- 知识库+知识图谱的结果：为知识库引入知识图谱的图形化结构，将知识库中的数据相互关联，使得信息不仅仅是简单的事实，呈现出实体之间的多维关系和上下文语境。

![RAG流程图](../../../blogs/imgs/Tricks/01%20基础概念-RAG流程图.png)

---

## Fine-Tuning 微调

**微调核心概念**

大模型微调（Fine-tuning）是指在已经预训练好的大型深度学习模型基础上，使用新的、特定任务相关的数据集对模型进行进一步训练的过程。主要目的是使模型能够适应新的、具体的任务或领域，而无需从头开始训练一个全新的模型。

- 优点：模型可以专注于具体任务的细节，从而提高在特定任务上的表现，在特定任务中更好地捕捉任务相关的特征和模式，也可以使模型快速适应新的领域或任务。
- 缺点：微调大型预训练模型需要较为强大的硬件支持，如7b的模型选择全量微调和不做量化版至少需要120G的显存，另外在微调过程中，模型有可能忘记以前学到的通用知识，尤其是在微调数据与以前的数据差异较大的情况下。

![通用微调流程图](../../../blogs/imgs/Tricks/01%20基础概念-通用微调流程图.png)

---

## 常见微调算法

**Full Fine-Tuning全量微调**

全量微调是指对预训练模型的所有参数进行调整和优化。在这种方法中，模型的所有权重（包括网络中的每一层和每个连接的权重）都会在新任务的训练过程中被更新。

- 优点：在数据充足的情况下，能够充分利用微调数据，提高模型的表现。
- 缺点：需要大量的计算资源和存储空间。

**Low-Rank Adaptation 低秩适配微调**

LoRA微调是一种参数高效的微调方法。在LoRA中模型的每一层的权重矩阵会被分解成低秩矩阵的和，并且仅更新这些低秩矩阵的参数，而保持原始的预训练权重不变。

- 优点：相比全量微调，所需的计算资源和存储空间大大减少。不会对预训练模型的结构产生太大影响。
- 缺点：任务难度较大时无法达到预期。产生更多的幻觉问题。

**Supervised Fine-Tuning 监督微调**

是指已有的预训练模型（大语言模型）已经经过大量无监督预训练之后，使用带标签的训练数据进行进一步的训练，目的是利用特定领域或特定任务的数据，进一步提升模型在该任务上的表现。

- 优点：指导模型在更特定任务上生成更准确和更相关的回答。
- 缺点：监督微调依赖于高质量、充分标注的数据集。

![实施微调流程图](../../../blogs/imgs/Tricks/01%20基础概念-实施微调流程图.png)

---

## 大模型压缩技术

**量化（Quantization）：**
- 减少模型中数值表示精度的方式来减小模型大小和推理过程的技术
    - 降低硬件要求
    - 量化可能会导致一定的精度损失

**蒸馏（Knowledge Distillation）：**
- 通过让一个较小的模型模仿一个较大且性能更好的模型的行为，从而使得小模型学习到大模型的“知识”
    - 让小模型拥有大模型的能力
    - 小模型的训练过程依赖于大模型的能力

**剪枝（Pruning）：**
- 去除神经网络中不重要或冗余的权重连接来减少模型大小
    - 剪枝后模型更小，计算更高效
    - 剪枝过程需对每一层、每一个参数的剪除进行仔细设计

---

## 人工智能行业资讯

**人工智能行业重要资讯　（2024年6月 ~ 至今）**

- **2022年11月30日**

    - ChatGPT问世！OpenAI全新对话式AI模型ChatGPT正式发布
- **2024年6月**

    - 皓客航空正式踏入人工智能赛道
    - 中国生成式人工智能用户规模增长：截至2024年6月，中国生成式人工智能产品的用户规模已经达到了2.3亿人，占全国总人口的16.4%
- **2024年7月**

    - 2024世界人工智能大会召开：7月4日至6日，2024世界人工智能大会在上海召开，聚焦大模型、算力、机器人、自动驾驶等“AI+”热门领域
    - 中国生成式人工智能服务大模型数量：截至2024年7月，中国已上线并备案的生成式人工智能服务大模型超过190个
- **2024年8月**

    - 智谱AI宣布开源了CogVideoX视频生成模型。将AI视频领域的竞争推向了新的高度。
- **2024年9月**

    - Gartner发布技术成熟度曲线：Gartner发布2024年中国数据、分析和人工智能技术成熟度曲线，预测未来两到五年内，大量具有颠覆性或较高影响力的创新技术可能会实现主流采用
    - AI领域动态：包括谷歌和Meta发布新的AI模型，AI语音机器人的发展等
- **2024年10月**

    - 全球人工智能领域的重大事件盘点：包括Meta的Llama 3.2模型展示、《2024年人工智能指数报告》发布等
    - 《2024 人工智能十大前沿技术趋势展望》发布：10月23日，在北京发布，涵盖了AI共性技术、大规模预训练模型、具身智能以及生成式人工智能等多个前沿领域
    - 华为推出AI处理器“昇腾 5”：10月29日，华为宣布推出其最新的AI处理器“昇腾 5”，在性能和能效上均实现了突破
- **2024年11月**

    - 中国信通院发布《人工智能发展报告（2024年）》：报告深入分析了人工智能技术的最新发展趋势和未来展望
    - 中国生成式AI大会（上海站）：12月5-6日，2024中国生成式AI大会（上海站）「GenAICon 2024」将在上海中星铂尔曼大酒店举办
- **2024年12月**

    - 全国工商联人工智能委员会成立：12月2日，全国工商联人工智能委员会在南京正式成立，旨在贯彻落实党的二十届三中全会精神，扩大统战工作在人工智能领域的影响
    - 《2024年人工智能十大前沿技术趋势展望》发布：在2024年世界科技与发展论坛期间发布，旨在构建开放合作的人工智能技术发展趋势

---

## 其他资料

**皓客内部AI技术分享**
- 第一次：基础认知及Prompt提示词工程
- 第二次：知识库、知识图谱和RAG
- 第三次：大模型压缩及微调技术
    - PPT地址（公司服务器）：\\SERVER\01 HAWK_Public\07  培训类\03 公司内训课程\AI技术应用系列培训\01 AI 技术分享-高赛菲
